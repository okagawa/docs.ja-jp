---
title: サービス間の通信
description: バックエンドクラウドネイティブマイクロサービスが他のバックエンドマイクロサービスと通信する方法について説明します。
author: robvet
ms.date: 05/13/2020
ms.openlocfilehash: dec06cc28ac177381b882f9e441e19e5c51bd5ad
ms.sourcegitcommit: 27db07ffb26f76912feefba7b884313547410db5
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 05/19/2020
ms.locfileid: "83613708"
---
# <a name="service-to-service-communication"></a>サービス間の通信

フロントエンドクライアントから、バックエンドマイクロサービスが相互に通信できるようになりました。

クラウドネイティブアプリケーションを構築する場合は、バックエンドサービスが相互に通信する方法を区別する必要があります。 理想的には、サービス間の通信が少なくて済むということです。 ただし、バックエンドサービスが操作を完了するために相互に依存していることが多いため、回避することは常に可能であるとは限りません。

サービス間通信の実装には、広く受け入れられている方法がいくつかあります。 多くの場合、*通信の相互作用の種類*によって最適な方法が決定されます。

次のような相互作用の種類を考えてみます。

- *クエリ*–呼び出し側のマイクロサービスが、"特定の顧客 Id の購入者情報を提供します" など、呼び出されたマイクロサービスからの応答を必要とする場合。

- *コマンド*–呼び出しを行うマイクロサービスが、アクションを実行するために別のマイクロサービスを必要としているが、応答を必要としない場合 (この注文を発送するだけです)。

- *イベント*–発行元と呼ばれるマイクロサービスが、状態が変更されたか、アクションが発生したことを示すイベントを発生させます。 サブスクライバーと呼ばれるその他のマイクロサービスは、イベントに適切に反応できます。 パブリッシャーとサブスクライバーが互いを認識していません。

マイクロサービスシステムは、通常、サービス間の対話を必要とする操作を実行するときに、これらの相互作用の種類を組み合わせて使用します。 それぞれの方法と、それらを実装する方法について詳しく見ていきましょう。

## <a name="queries"></a>クエリ

多くの場合、1つのマイクロサービスが別のマイクロサービスに*クエリ*を実行し、操作を完了するために直ちに対応する必要がある場合があります。 買い物かごマイクロサービスでは、商品情報と、バスケットに商品を追加するための料金が必要になる場合があります。 クエリ操作を実装するには、いくつかの方法があります。

### <a name="requestresponse-messaging"></a>要求/応答メッセージング

このシナリオを実装するための1つのオプションは、図4-8 に示すように、バックエンドマイクロサービスを呼び出して、クエリを実行する必要があるマイクロサービスに対して HTTP 要求を直接実行することです。

![直接 HTTP 通信](./media/direct-http-communication.png)

**図 4-8** 直接 HTTP 通信

マイクロサービス間の直接 HTTP 呼び出しを実装するのは比較的簡単ですが、この方法を最小限に抑えるために注意する必要があります。 を開始するために、これらの呼び出しは常に*同期*的であり、結果が返されるか、または要求がタイムアウトするまで、操作をブロックします。 自己完結型、独立したサービス、個別に進化し、頻繁に展開できることは、相互に結合されるようになりました。 マイクロサービス間の結合が増加するにつれて、アーキテクチャ上のメリットが減少します。

別のマイクロサービスに対して単一の直接 HTTP 呼び出しを行う頻度の低い要求を実行すると、一部のシステムで許容される可能性があります。 ただし、複数のマイクロサービスに対して直接 HTTP 呼び出しを呼び出す大量の呼び出しは推奨されません。 待機時間が長くなり、システムのパフォーマンス、スケーラビリティ、可用性に悪影響を及ぼす可能性があります。 さらに悪いことに、次の図4-9 に示すように、長い一連の直接 HTTP 通信によって、同期マイクロサービス呼び出しの深いチェーンが複雑になる可能性があります。

![HTTP クエリのチェーン](./media/chaining-http-queries.png)

**図 4-9** HTTP クエリのチェーン

前の図に示されている設計のリスクを考えてみてください。 手順 \# 3. が失敗した場合はどうなりますか。 または手順 \# 8 に失敗しますか? どのように回復すればよいですか。 \#基になるサービスがビジー状態であるために手順6が遅い場合はどうすればよいでしょうか。 続行するにはどうすればよいですか。 すべてが正しく動作する場合でも、この呼び出しで発生する待機時間を考慮してください。これは、各ステップの待機時間の合計です。

前の図に示した大規模な結合により、サービスが最適にモデル化されていないことがわかります。 チームによる設計の見直しに behoove ます。

### <a name="materialized-view-pattern"></a>具体化されたビュー パターン

マイクロサービスの結合を削除するための一般的なオプションは、具体化された[ビューパターン](https://docs.microsoft.com/azure/architecture/patterns/materialized-view)です。 このパターンでは、マイクロサービスは、他のサービスによって所有されている独自のローカルの非正規化されたデータのコピーを格納します。 製品カタログと料金マイクロサービスを照会するショッピングバスケットマイクロサービスではなく、そのデータのローカルコピーを保持します。 このパターンは、不要な結合を排除し、信頼性と応答時間を向上させます。 操作全体が1つのプロセス内で実行されます。 このパターンと、5章のその他のデータの問題について説明します。

### <a name="service-aggregator-pattern"></a>サービスアグリゲーターパターン

マイクロサービスからマイクロサービスへの結合を排除するもう1つのオプションは、図4-10 の紫色の[マイクロサービス](https://devblogs.microsoft.com/cesardelatorre/designing-and-implementing-api-gateways-with-ocelot-in-a-microservices-and-container-based-architecture/)です。

![アグリゲーターサービス](./media/aggregator-service.png)

**図 4-10** アグリゲーターマイクロサービス

このパターンは、複数のバックエンドマイクロサービスへの呼び出しを行う操作を分離し、そのロジックを専用のマイクロサービスに一元化します。  前の図の紫色のチェックアウトアグリゲーターマイクロサービスは、チェックアウト操作のワークフローを調整します。 シーケンス処理された順序で、複数のバックエンドマイクロサービスを呼び出すことができます。 ワークフローからのデータが集計され、呼び出し元に返されます。 直接の HTTP 呼び出しを実装しますが、アグリゲーターマイクロサービスは、バックエンドマイクロサービス間の直接的な依存関係を減らします。

### <a name="requestreply-pattern"></a>要求/応答パターン

同期 HTTP メッセージを分離するためのもう1つの方法は、キュー通信を使用する[要求/応答パターン](https://www.enterpriseintegrationpatterns.com/patterns/messaging/RequestReply.html)です。 キューを使用した通信は、常に一方向のチャネルであり、プロデューサーがメッセージを送信し、コンシューマーがメッセージを受信します。 このパターンでは、図4-11 に示すように、要求キューと応答キューの両方が実装されます。

![要求/応答パターン](./media/request-reply-pattern.png)

**図 4-11** 要求/応答パターン

ここでは、メッセージプロデューサーが一意の相関 ID を含むクエリベースのメッセージを作成し、それを要求キューに配置します。 コンシューマーサービスはメッセージをデキューし、処理して応答を同じ相関 ID を持つ応答キューに配置します。 プロデューサーサービスはメッセージをデキューし、関連付け ID と照合して処理を続行します。 キューについては、次のセクションで詳しく説明します。

## <a name="commands"></a>コマンド

別の種類の通信相互作用は*コマンド*です。 マイクロサービスでは、アクションを実行するために別のマイクロサービスが必要になる場合があります。 注文マイクロサービスでは、承認された注文の発送を作成するために出荷マイクロサービスが必要になる場合があります。 図4-12 では、プロデューサーと呼ばれる1つのマイクロサービスが、別のマイクロサービス (コンシューマー) にメッセージを送信して、処理を実行しています。

![コマンドとキューのやり取り](./media/command-interaction-with-queue.png)

**図 4-12**. コマンドとキューのやり取り

ほとんどの場合、プロデューサーは応答を必要とせず、メッセージを*起動し忘れ*てしまう可能性があります。 応答が必要な場合、コンシューマーは別のチャネルでプロデューサーに別のメッセージを送り返します。 コマンドメッセージは、メッセージキューを使用して非同期に送信することをお勧めします。 ライトウェイトメッセージブローカーでサポートされます。 前の図では、キューが両方のサービスを分離および分離する方法に注意してください。

メッセージキューは、プロデューサーとコンシューマーがメッセージを渡す中間構造です。 キューは、非同期のポイントツーポイントのメッセージングパターンを実装します。 プロデューサーは、コマンドを送信する必要がある場所を認識し、適切にルーティングします。 キューは、チャネルから読み取るコンシューマーインスタンスの1つだけがメッセージを処理することを保証します。 このシナリオでは、プロデューサーまたはコンシューマーサービスは、もう一方に影響を与えずにスケールアウトできます。 また、テクノロジは互いに異なる場合があります。つまり、Java マイクロサービスが[Golang](https://golang.org)マイクロサービスを呼び出す可能性があります。

第1章では、*サービスのバックアップ*について説明しました。 バッキングサービスは、クラウドネイティブシステムが依存する補助的なリソースです。 メッセージキューは、バッキングサービスです。 Azure クラウドでは、クラウドネイティブシステムがコマンドメッセージングを実装するために使用できる2種類のメッセージキューをサポートしています。 Azure Storage キューと Azure Service Bus キューです。

### <a name="azure-storage-queues"></a>Azure Storage キュー

Azure storage キューは、Azure ストレージアカウントによってサポートされる、高速で手頃な価格の単純なキューインフラストラクチャを提供します。

[Azure Storage キュー](https://docs.microsoft.com/azure/storage/queues/storage-queues-introduction)は、信頼性の高い永続的なメッセージング機能を備えた REST ベースのキューメカニズムを備えています。 これらは最小限の機能セットを提供しますが、安価で、数百万のメッセージを格納します。 容量の範囲は最大 500 TB です。 1つのメッセージのサイズは最大 64 KB です。

HTTP または HTTPS を使用した認証された呼び出しを介して、世界中のどこからでもメッセージにアクセスできます。 ストレージキューは、多数の同時実行クライアントにスケールアウトして、トラフィックの急増に対応できます。

ただし、サービスには制限があります。

- メッセージの順序は保証されません。

- メッセージは、自動的に削除される7日間だけ保持できます。

- 状態管理、重複検出、またはトランザクションのサポートは使用できません。

図4-13 は、Azure Storage キューの階層を示しています。

![ストレージキューの階層](./media/storage-queue-hierarchy.png)

**図 4-13**. ストレージキューの階層

前の図では、storage キューによって、基になる Azure Storage アカウントにメッセージがどのように格納されているかを確認してください。

開発者向けに、Microsoft では、ストレージキュー処理用のクライアントとサーバー側のライブラリをいくつか提供しています。 .NET、Java、JavaScript、Ruby、Python、およびゴーを含むほとんどの主要なプラットフォームがサポートされています。 開発者は、これらのライブラリと直接通信することはできません。 これにより、マイクロサービスコードが Azure Storage Queue サービスに密に結合されます。 API の実装の詳細を分離することをお勧めします。 汎用操作を公開し、具象ライブラリをカプセル化する intermediation レイヤー (中間 API) を導入します。 この疎結合により、メインラインサービスコードを変更することなく、1つのキューサービスを別のキューサービスにスワップアウトできます。

Azure Storage キューは、クラウドネイティブアプリケーションにコマンドメッセージングを実装するための経済的なオプションです。 特に、キューのサイズが 80 GB を超える場合や、単純な機能セットが許容される場合です。 料金は、メッセージのストレージに対してのみ課金されます。時間単位の固定料金はありません。

### <a name="azure-service-bus-queues"></a>Azure Service Bus キュー

より複雑なメッセージング要件については、Azure Service Bus キューを検討してください。

[Azure Service Bus](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-messaging-overview)は、堅牢なメッセージインフラストラクチャを構築しています。*仲介型メッセージングモデル*がサポートされています。 メッセージは、コンシューマーによって受信されるまで、ブローカー (キュー) に確実に格納されます。 キューは、メッセージがキューに追加された順序に従って、先入れ先出し (FIFO) のメッセージ配信を保証します。

メッセージのサイズは、最大 256 KB まで、非常に大きくなる可能性があります。 メッセージは、無期限にキューに保持されます。 Service Bus は、HTTP ベースの呼び出しだけでなく、 [Amqp プロトコル](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-amqp-overview)の完全なサポートも提供します。 AMQP は、バイナリプロトコルと高い信頼性をサポートするベンダー全体のオープン標準です。

Service Bus には、[トランザクションのサポート](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-transactions)や[重複検出機能](https://docs.microsoft.com/azure/service-bus-messaging/duplicate-detection)など、豊富な機能セットが用意されています。 キューは、メッセージごとに "最大で1回の配信" を保証します。 既に送信済みのメッセージは自動的に破棄されます。 プロデューサーが不明な場合は、同じメッセージを再送信し、1つのコピーのみが処理されることを保証 Service Bus ます。 重複検出を使用すると、インフラストラクチャの追加の組み込みを構築する必要がなくなります。

さらに、パーティション分割とセッションという2つのエンタープライズ機能があります。 従来の Service Bus キューは、1つのメッセージブローカーによって処理され、1つのメッセージストアに格納されます。 ただし、 [Service Bus パーティション分割](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-partitioning)では、複数のメッセージブローカーとメッセージストアにキューを分散します。 全体のスループットは、1つのメッセージブローカーまたはメッセージングストアのパフォーマンスによって制限されなくなりました。 メッセージングストアが一時的に停止しても、パーティション分割されたキューは表示されません。

[Service Bus セッション](https://codingcanvas.com/azure-service-bus-sessions/)は、グループに関連するメッセージの方法を提供します。 メッセージをまとめて処理し、最後に操作を完了するワークフローシナリオを想像してみてください。 利用するには、キューに対してセッションを明示的に有効にする必要があります。また、関連する各メッセージに同じセッション ID が含まれている必要があります。

ただし、いくつかの重要な注意点があります。 Service Bus キューのサイズは 80 GB に制限されています。これは、ストアキューで使用できるものよりもはるかに小さくなっています。 また、Service Bus キューには、操作ごとに基本コストと料金が発生します。

図4-14 は、Service Bus キューのアーキテクチャの概要を示しています。

![Service Bus キュー](./media/service-bus-queue.png)

**図 4-14**. Service Bus キュー

前の図では、ポイントツーポイントの関係に注意してください。 同じプロバイダーの2つのインスタンスは、メッセージを1つの Service Bus キューにエンキューします。 各メッセージは、右側にある3つのコンシューマーインスタンスのうちの1つのみによって使用されます。 次に、さまざまなコンシューマーが同じメッセージに関心を持つ可能性があるメッセージングを実装する方法について説明します。

## <a name="events"></a>イベント

メッセージキューは、プロデューサーがコンシューマーにメッセージを非同期に送信できる通信を実装するための効果的な方法です。 しかし、同じメッセージに*多くの異なるコンシューマー*が関心を持っている場合はどうなるでしょうか。 コンシューマーごとに専用のメッセージキューが拡張されることはなく、管理が困難になります。

このシナリオに対処するために、メッセージの相互作用 (*イベント*) の3番目の種類に移ります。 1つのマイクロサービスによってアクションが発生したことが通知されます。 他のマイクロサービス (関心がある場合) は、アクションまたはイベントに反応します。

イベント処理は2段階のプロセスです。 特定の状態の変更に対して、マイクロサービスはイベントをメッセージブローカに発行し、他の任意のマイクロサービスで使用できるようにします。 関心のあるマイクロサービスは、メッセージブローカーでイベントをサブスクライブすることによって通知されます。 [イベントベースの通信](https://docs.microsoft.com/dotnet/standard/microservices-architecture/multi-container-microservice-net-applications/integration-event-based-microservice-communications)を実装するには、[発行/サブスクライブ](https://docs.microsoft.com/azure/architecture/patterns/publisher-subscriber)パターンを使用します。

図4-15 は、2つの他のマイクロサービスがサブスクライブしているイベントを発行する買い物かごマイクロサービスを示しています。

![イベントドリブンメッセージング](./media/event-driven-messaging.png)

**図 4-15**. イベントドリブンメッセージング

通信チャネルの中央にある*イベントバス*コンポーネントに注意してください。 これは、メッセージブローカーをカプセル化し、基になるアプリケーションから分離するカスタムクラスです。 注文とインベントリのマイクロサービスは、個別にイベントを操作します。また、ショッピングカートマイクロサービスについての知識も不要です。 登録されたイベントは、イベントバスに発行されると、動作します。

イベントによって、キューテクノロジから*トピック*に移動します。 [トピック](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-dotnet-how-to-use-topics-subscriptions)はキューに似ていますが、1対多のメッセージングパターンをサポートしています。 1つのマイクロサービスがメッセージを公開します。 複数のサブスクライブマイクロサービスは、そのメッセージの受信と操作を選択できます。 図4-16 に、トピックアーキテクチャを示します。

![トピックのアーキテクチャ](./media/topic-architecture.png)

**図 4-16**. トピックのアーキテクチャ

前の図では、パブリッシャーがトピックにメッセージを送信しています。 最後に、サブスクライバーはサブスクリプションからメッセージを受信します。 中央では、トピックは、一連の*ルール*に基づいてメッセージを (濃い青色のボックスに表示される) サブスクリプションに転送します。 ルールは、特定のメッセージをサブスクリプションに転送するフィルターとして機能します。 ここでは、"CreateOrder" イベントはサブスクリプション1とサブスクリプション3に送信されますが、サブスクリプション2には送信され \# \# ません \# 。 "OrderCompleted" イベントは、サブスクリプション \# 2 とサブスクリプション3に送信され \# ます。

Azure クラウドでは、Azure Service Bus トピックと Azure EventGrid という2つの異なるトピックサービスがサポートされています。

### <a name="azure-service-bus-topics"></a>Azure Service Bus トピック

Azure Service Bus キューの堅牢な仲介型メッセージモデルと同じように、 [Azure Service Bus のトピック](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-dotnet-how-to-use-topics-subscriptions)もあります。 トピックは、複数の独立したパブリッシャーからメッセージを受信し、最大2000のサブスクライバーにメッセージを送信できます。 実行時にサブスクリプションを動的に追加または削除するには、システムを停止するか、トピックを再作成します。

Azure Service Bus キューの多くの高度な機能は、[重複の検出](https://docs.microsoft.com/azure/service-bus-messaging/duplicate-detection)やトランザクションの[サポート](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-transactions)などのトピックでも使用できます。 既定では、Service Bus のトピックは1つのメッセージブローカーによって処理され、1つのメッセージストアに格納されます。 ただし、 [Service Bus パーティション分割](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-partitioning)では、多数のメッセージブローカーとメッセージストアに分散することによってトピックをスケーリングします。

[スケジュール](https://docs.microsoft.com/azure/service-bus-messaging/message-sequencing)されたメッセージの配信では、特定の処理時間のメッセージにタグが付けられます。 このメッセージは、その時点より前のトピックには表示されません。 [メッセージの遅延](https://docs.microsoft.com/azure/service-bus-messaging/message-deferral)により、メッセージの取得を後で遅らせることができます。 どちらも、操作が特定の順序で処理されるワークフロー処理のシナリオでよく使用されます。 前の作業が完了するまで、受信したメッセージの処理を延期することができます。

Service Bus トピックは、クラウドネイティブシステムで公開/サブスクライブ通信を有効にするための堅牢で実証されたテクノロジです。

### <a name="azure-event-grid"></a>Azure Event Grid

Azure Service Bus は、エンタープライズ機能の完全なセットを備えた、徹底的にテストされたメッセージングブローカーですが、 [Azure Event Grid](https://docs.microsoft.com/azure/event-grid/overview)はブロックの新しい kid です。

一見すると、Event Grid は別のトピックベースのメッセージングシステムのように見えます。 ただし、多くの点で異なります。 イベントドリブンなワークロードに重点を置いて、サーバーレスインフラストラクチャでのリアルタイムイベント処理、ディープ Azure 統合、オープンプラットフォームのすべての機能を実現します。 最新のクラウドネイティブアプリケーションとサーバーレスアプリケーション向けに設計されています。

一元化されたイベント*バックプレーン*(パイプ) として、Event Grid は、Azure リソース内および独自のサービスからのイベントに反応します。

イベント通知は Event Grid トピックにパブリッシュされます。これにより、各イベントがサブスクリプションにルーティングされます。 サブスクライバーはサブスクリプションにマップされ、イベントを使用します。 Service Bus と同様に、Event Grid では、受信するイベントのルールがサブスクリプションによって設定されるフィルター選択された*サブスクライバーモデル*がサポートされます。 Event Grid は、1秒あたり1000万イベントの保証によって高速スループットを実現し、ほぼリアルタイムの配信を可能にします。これにより、Azure Service Bus によって生成される可能性がはるかに高くなります。

Event Grid のために、Azure インフラストラクチャのファブリックに深く統合されています。 Azure リソース (Cosmos DB など) は、組み込みのイベントを他の関心のある Azure リソースに直接発行できます。カスタムコードは必要ありません。 Event Grid は、Azure サブスクリプション、リソースグループ、またはサービスからイベントを発行できるため、開発者はクラウドリソースのライフサイクルをきめ細かく制御できます。 ただし、Event Grid は Azure に限定されません。 これは、アプリケーションまたはサードパーティのサービスから発行されたカスタム HTTP イベントを使用したり、イベントを外部サブスクライバーにルーティングしたりできるオープンプラットフォームです。

Azure リソースからネイティブイベントを発行およびサブスクライブする場合、コーディングは必要ありません。 単純な構成では、トピックとサブスクリプションの組み込みの組み込み機能を利用して、ある Azure リソースのイベントを別のリソースに統合できます。 図4-17 は、Event Grid の構造を示しています。

![Event Grid の構造](./media/event-grid-anatomy.png)

**図 4-17**.  Event Grid の構造

EventGrid と Service Bus の主な違いは、基になる*メッセージ交換パターン*です。

Service Bus には、古いスタイルの*プルモデル*が実装されています。このモデルでは、ダウンストリームサブスクライバーが新しいメッセージのトピックサブスクリプションをアクティブにポーリングします。 この方法を使用すると、サブスクライバーはメッセージを処理するペースを完全に制御できます。 特定の時点で処理するメッセージのタイミングと数を制御します。 未読のメッセージは、処理されるまでサブスクリプションに残ります。 重大な欠点は、イベントが生成されてから、そのメッセージを処理のためにサブスクライバーにプルするポーリング操作までの待機時間です。 また、次のイベントの定数ポーリングのオーバーヘッドによって、リソースとコストが消費されます。

ただし、EventGrid は異なります。 これは、イベントが受信時に EventHandlers に送信される*プッシュモデル*を実装し、ほぼリアルタイムのイベント配信を提供します。 また、ポーリングと同様に継続的にではなく、イベントを使用する必要がある場合にのみ、サービスがトリガーされるため、コストを削減できます。 ただし、イベントハンドラーは受信負荷を処理し、それ自体が過負荷になるのを防ぐための調整メカニズムを提供する必要があります。 Azure Functions や Logic Apps など、これらのイベントを使用する多くの Azure サービスでは、増加した負荷を処理する自動自動スケール機能が提供されます。  

Event Grid は、完全に管理されたサーバーレスクラウドサービスです。 トラフィックに基づいて動的に拡張され、購入済みの容量ではなく実際の使用量に対してのみ課金されます。 1か月あたりの最初の10万操作は無料です。イベントの受信 (受信イベント通知) として定義されている操作、サブスクリプションの配信試行、管理呼び出し、およびサブジェクト別のフィルター処理です。 99.99% の可用性により、EventGrid は24時間以内にイベントの配信を保証し、配信に失敗した場合の組み込みの再試行機能を備えています。 配信されていないメッセージは、解決のために "配信不能" キューに移動できます。  Azure Service Bus とは異なり、Event Grid は高速なパフォーマンスのためにチューニングされており、順序付けされたメッセージング、トランザクション、セッションなどの機能をサポートしていません。

### <a name="streaming-messages-in-the-azure-cloud"></a>Azure クラウドでのメッセージのストリーミング

Azure Service Bus と Event Grid は、新しいドキュメントのような単一の独立したイベントを公開するアプリケーションに対して、Cosmos DB に挿入された優れたサポートを提供します。 しかし、クラウドネイティブシステムで*関連イベントのストリーム*を処理する必要がある場合はどうでしょうか。 [イベントストリーム](https://docs.microsoft.com/archive/msdn-magazine/2015/february/microsoft-azure-the-rise-of-event-stream-oriented-systems)はより複雑です。 通常は、時間順で相互関係があり、グループとして処理する必要があります。

[Azure Event Hub](https://azure.microsoft.com/services/event-hubs/)は、イベントを収集、変換、および格納するデータストリーミングプラットフォームおよびイベントインジェストサービスです。 テレメトリコンテキストから生成された継続的なイベント通知など、ストリーミングデータをキャプチャするために微調整されています。 このサービスは、拡張性が高く、 [1 秒あたり何百万ものイベント](https://docs.microsoft.com/azure/event-hubs/event-hubs-about)を格納および処理できます。 図4-18 に示すように、多くの場合、イベントパイプラインのフロントドアとして、取り込みストリームをイベントの消費から切り離します。

![Azure Event Hub](./media/azure-event-hub.png)

**図 4-18**. Azure Event Hub

イベントハブでは、短い待機時間と構成可能な時間のリテンション期間がサポートされます。 キューやトピックとは異なり、コンシューマーによって読み取られた後にイベントデータを保持 Event Hubs ます。 この機能により、内部および外部の他のデータ分析サービスは、データを再生してさらに分析することができます。 イベントハブに格納されているイベントは、保有期間の有効期限が切れたときにのみ削除されます。既定では1日ですが、構成することができます。

イベントハブでは、HTTPS や AMQP などの一般的なイベント発行プロトコルがサポートされています。 Kafka 1.0 もサポートしています。 [既存の kafka アプリケーションは](https://docs.microsoft.com/azure/event-hubs/event-hubs-for-kafka-ecosystem-overview)、大規模な kafka クラスターを管理する代わりに、kafka プロトコルを使用して Event Hub と通信できます。 オープンソースのクラウドネイティブシステムの多くは、Kafka を採用しています。

Event Hubs は、メッセージストリームの特定のサブセット (パーティション) のみを読み取る、パーティション分割された[コンシューマーモデル](https://docs.microsoft.com/azure/event-hubs/event-hubs-features)を介してメッセージストリーミングを実装します。 このパターンでは、イベント処理の横の倍率を大きくすることができ、キューおよびトピックで使用できないその他のストリームに重点を置いた機能を提供します。 パーティションは、イベント ハブで保持される順序付けされた一連のイベントです。 新しいイベントが到着すると、このシーケンスの末尾に追加されます。図4-19 は、イベントハブでのパーティション分割を示しています。

![イベントハブのパーティション分割](./media/event-hub-partitioning.png)

**図 4-19** イベントハブのパーティション分割

各コンシューマーグループは、同じリソースから読み取るのではなく、メッセージストリームのサブセットまたはパーティションをまたいで読み取ります。

多数のイベントをストリーミングする必要があるクラウドネイティブアプリケーションの場合、Azure Event Hub は堅牢で手頃な価格のソリューションになります。

>[!div class="step-by-step"]
>[前へ](front-end-communication.md)
>[次へ](grpc.md)
